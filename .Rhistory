wgts0 <- wgts[idx.seq] / sum(wgts[idx.seq])
new.pgram[i.freq] <- sum(wgts0*raw.pgram[(i.freq-m):n.freq])
}
return(new.pgram)
}
# For unweighted smoothing with m=4, hence L=2*m+1=9, define the weights as follows
m <- 4
L <- 2*m + 1
wgts <- rep(x=1/L, times=L)
wgts
# Smoothed periodograms and corresponding plots are generated as follows:
soi.spgram <- smooth.pgram(soi.pgram, wgts)
rec.spgram <- smooth.pgram(rec.pgram, wgts)
n.yr <- 453/12
freq.seq <- 1:ceiling(6*n.yr)
freq.idx <- freq.seq+1
par(mfrow = c(2, 1), mai=c(0.50,1.00,0.1,0.1)) # mai=c(bottom, left, top, right)
plot(freq.seq/n.yr, soi.spgram[freq.idx], type="l", lty=1, lwd=1, ylab="Unweighted smoothing", xlab="Frequency")
abline(v=1/4, lty=2)
plot(freq.seq/n.yr, rec.spgram[freq.idx], type="l", lty=1, lwd=1, ylab="Unweighted smoothing", xlab="Frequency")
abline(v=1/4, lty=2)
par(mfrow = c(1, 1))
# ---------------------------------------------------------------------------------
# Confidence intervals
# ---------------------------------------------------------------------------------
# The confidence interval calculation carried out in part A of the learning unit may be repeated on the smoothed periodogram.
# With a smoothed periodogram, chi-square quantiles are calculated using a special formula for degrees of freedom:
df <- 2/sum(wgts^2)
# When the weights are uniform, as they are in this example, this value is identical to the value 2L, the length of the weights.
c(2L, df)
# Confidence intervals for the periodogram associated with the one-year (omega=1/12) cycles and four-year (omega=1/48) cycles are calculated as follows.
# The value associated with the one year cycle found at element 39 of the periodogram vector.
i.val <- 39
# Confidence intervals are calculated as follows
alpha <- 0.05
cutoff <- qchisq(p=c(alpha/2, 1-alpha/2), df=df)
# SOI time series
val <- soi.spgram[i.val]
lo.bnd <- df*val/cutoff[2]
hi.bnd <- df*val/cutoff[1]
print(paste("Point estimate: ", sprintf("%6.4f", val), sep=""))
print(paste(sprintf("%2.0f", (1-alpha)*100), "% confidence interval: [", sprintf("%6.4f", lo.bnd), ", ", sprintf("%6.4f", hi.bnd), "]", sep=""))
print("Log transform:")
print(paste("Point estimate: ", sprintf("%6.4f", log(val)), sep=""))
print(paste(sprintf("%2.0f", (1-alpha)*100), "% confidence interval: [", sprintf("%6.4f", log(lo.bnd)), ", ", sprintf("%6.4f", log(hi.bnd)), "]", sep=""))
# Fish population count time series
val <- rec.spgram[i.val]
lo.bnd <- df*val/cutoff[2]
hi.bnd <- df*val/cutoff[1]
print(paste("Point estimate: ", sprintf("%6.4f", val), sep=""))
print(paste(sprintf("%2.0f", (1-alpha)*100), "% confidence interval: [", sprintf("%6.4f", lo.bnd), ", ", sprintf("%6.4f", hi.bnd), "]", sep=""))
print("Log transform:")
print(paste("Point estimate: ", sprintf("%6.4f", log(val)), sep=""))
print(paste(sprintf("%2.0f", (1-alpha)*100), "% confidence interval: [", sprintf("%6.4f", log(lo.bnd)), ", ", sprintf("%6.4f", log(hi.bnd)), "]", sep=""))
# The value associated with the four year cycle found at element 10 of the periodogram vector.
i.val <- 10
# The associated confidence intervals are calculated as follows
# SOI time series
val <- soi.spgram[i.val]
lo.bnd <- df*val/cutoff[2]
hi.bnd <- df*val/cutoff[1]
print(paste("Point estimate: ", sprintf("%6.4f", val), sep=""))
print(paste(sprintf("%2.0f", (1-alpha)*100), "% confidence interval: [", sprintf("%6.4f", lo.bnd), ", ", sprintf("%6.4f", hi.bnd), "]", sep=""))
print("Log transform:")
print(paste("Point estimate: ", sprintf("%6.4f", log(val)), sep=""))
print(paste(sprintf("%2.0f", (1-alpha)*100), "% confidence interval: [", sprintf("%6.4f", log(lo.bnd)), ", ", sprintf("%6.4f", log(hi.bnd)), "]", sep=""))
# Fish population count time series
val <- rec.spgram[i.val]
lo.bnd <- df*val/cutoff[2]
hi.bnd <- df*val/cutoff[1]
print(paste("Point estimate: ", sprintf("%6.4f", val), sep=""))
print(paste(sprintf("%2.0f", (1-alpha)*100), "% confidence interval: [", sprintf("%6.4f", lo.bnd), ", ", sprintf("%6.4f", hi.bnd), "]", sep=""))
print("Log transform:")
print(paste("Point estimate: ", sprintf("%6.4f", log(val)), sep=""))
print(paste(sprintf("%2.0f", (1-alpha)*100), "% confidence interval: [", sprintf("%6.4f", log(lo.bnd)), ", ", sprintf("%6.4f", log(hi.bnd)), "]", sep=""))
# ---------------------------------------------------------------------------------
# Daniell kernels
# ---------------------------------------------------------------------------------
# A recursive algorithm that generates the weights of a Daniell kernel is coded into a user-defined function as follows. The algorithm begins with an initial set of weights and takes it through a give number of iterations through a refinement step.
Daniell.wgts <- function(base.wgts, n.iter) {
for (iter in 0:n.iter) {
if (iter == 0) {
L2 <- length(base.wgts)
wgts <- base.wgts
} else {
L2 <- 2*L1 - 1
wgts <- rep(x=0, times=L2)
for (i.wgt in 1:L1) {
wgts[i.wgt:(i.wgt+L1-1)] <- wgts[i.wgt:(i.wgt+L1-1)] + last.wgts[i.wgt]*last.wgts
}
}
last.wgts <- wgts
L1 <- L2
}
return(wgts)
}
# The weight calculation is demonstrated as follows. For initial exploration, start with an initial set of uniform weights of length L = 2*m + 1 = 3, which corresponds to the setting m=1. It is then passed through a single iteration of the refinement algorithm to produce a set of weights of length L = 2*m + 1 = 5, which corresponds to the setting m=2. Starting with an initial set of uniform weights produces what is called an "ordinary" Daniell kernel.
base.wgts.A <- c(1, 1, 1)/3
n.iter <- 1
wgts.A <- Daniell.wgts(base.wgts.A, n.iter)
wgts.A
# The following repeats the calculation using a different set of initial weights. This initial setting produces what is called an "modified" Daniell kernel.
base.wgts.B <- c(1, 2, 1)/4
wgts.B <- Daniell.wgts(base.wgts.B, n.iter)
wgts.B
# Notice that in all cases, the weights sum to one:
sum(base.wgts.A)
sum(wgts.A)
sum(base.wgts.B)
sum(wgts.B)
# Corresponding plots are generated as follows.
par(mfrow = c(2, 2), mai=c(0.50,1.00,0.1,0.1)) # mai=c(bottom, left, top, right)
disp.wgts <- base.wgts.A
L <- length(disp.wgts)
m <- 0.5*(L - 1)
plot(c(-m, m), c(0, 0), type="l", lty=2, lwd=1, xlim=c(-m-0.25, m+0.25), ylim=c(0, 1.1*max(disp.wgts)), col="white", ylab="weight", xlab="", main="base weights (0 iter)")
for (i.wgt in 1:L) {
lines((i.wgt-m-1)*c(1, 1), c(0, disp.wgts[i.wgt]), lty=1, lwd=3, col="blue")
}
abline(h=0, lty=2)
disp.wgts <- base.wgts.B
L <- length(disp.wgts)
m <- 0.5*(L - 1)
plot(c(-m, m), c(0, 0), type="l", lty=2, lwd=1, xlim=c(-m-0.25, m+0.25), ylim=c(0, 1.1*max(disp.wgts)), col="white", ylab="weight", xlab="", main="base weights (0 iter)")
for (i.wgt in 1:L) {
lines((i.wgt-m-1)*c(1, 1), c(0, disp.wgts[i.wgt]), lty=1, lwd=3, col="blue")
}
abline(h=0, lty=2)
disp.wgts <- wgts.A
L <- length(disp.wgts)
m <- 0.5*(L - 1)
plot(c(-m, m), c(0, 0), type="l", lty=2, lwd=1, xlim=c(-m-0.25, m+0.25), ylim=c(0, 1.1*max(disp.wgts)), col="white", ylab="weight", xlab="", main=paste("final weights (", n.iter, " iter)", sep=""))
for (i.wgt in 1:L) {
lines((i.wgt-m-1)*c(1, 1), c(0, disp.wgts[i.wgt]), lty=1, lwd=3, col="blue")
}
abline(h=0, lty=2)
disp.wgts <- wgts.B
L <- length(disp.wgts)
m <- 0.5*(L - 1)
plot(c(-m, m), c(0, 0), type="l", lty=2, lwd=1, xlim=c(-m-0.25, m+0.25), ylim=c(0, 1.1*max(disp.wgts)), col="white", ylab="weight", xlab="", main=paste("final weights (", n.iter, " iter)", sep=""))
for (i.wgt in 1:L) {
lines((i.wgt-m-1)*c(1, 1), c(0, disp.wgts[i.wgt]), lty=1, lwd=3, col="blue")
}
abline(h=0, lty=2)
par(mfrow = c(1, 1))
# Suppose instead the initial set of weights is
base.wgts <- c(1, 2, 2, 2, 2, 2, 1)/12
# The length of this set of weights is L = 2*m + 1 = 7, which corresponds to m=3. Passing it through one iteration of the refinement step produces a set of weights having length L = 2*m + 1 = 13, which corresponds to m=6.
n.iter <- 1
wgts <- Daniell.wgts(base.wgts, n.iter)
wgts
# The pattern here is that each iteration of the refinement step takes a set of weights having length L1 to a new set of weights having length L2 = 2*L1 - 1. In terms of the parameter m, the corresponding relationship is that a set of weights with that parameter at m=m1 expands to a set of weights with the parameter at m=m2=2*m1.
# A plot of the inital and final weights is generated by the following code.
par(mfrow = c(2, 1), mai=c(0.50,1.00,0.1,0.1)) # mai=c(bottom, left, top, right)
disp.wgts <- base.wgts
L <- length(disp.wgts)
m <- 0.5*(L - 1)
plot(c(-m, m), c(0, 0), type="l", lty=2, lwd=1, xlim=c(-m-0.25, m+0.25), ylim=c(0, 1.1*max(disp.wgts)), col="white", ylab="weight", xlab="", main="base weights (0 iter)")
for (i.wgt in 1:L) {
lines((i.wgt-m-1)*c(1, 1), c(0, disp.wgts[i.wgt]), lty=1, lwd=3, col="blue")
}
abline(h=0, lty=2)
disp.wgts <- wgts
L <- length(disp.wgts)
m <- 0.5*(L - 1)
plot(c(-m, m), c(0, 0), type="l", lty=2, lwd=1, xlim=c(-m-0.25, m+0.25), ylim=c(0, 1.1*max(disp.wgts)), col="white", ylab="weight", xlab="", main=paste("final weights (", n.iter, " iter)", sep=""))
for (i.wgt in 1:L) {
lines((i.wgt-m-1)*c(1, 1), c(0, disp.wgts[i.wgt]), lty=1, lwd=3, col="blue")
}
abline(h=0, lty=2)
par(mfrow = c(1, 1))
# ---------------------------------------------------------------------------------
# Smoothing with Daniell kernels
# ---------------------------------------------------------------------------------
# The following code produces smoothed periodograms and corresponding plots of the fish population count and SOI time series using the modified Daniell kernel specified above.
soi.spgram <- smooth.pgram(soi.pgram, wgts)
rec.spgram <- smooth.pgram(rec.pgram, wgts)
n.yr <- 453/12
freq.seq <- 1:ceiling(6*n.yr)
freq.idx <- freq.seq+1
par(mfrow = c(2, 1), mai=c(0.50,1.00,0.1,0.1)) # mai=c(bottom, left, top, right)
plot(freq.seq/n.yr, soi.spgram[freq.idx], type="l", lty=1, lwd=1, ylab="Weighted smoothing", xlab="Frequency")
abline(v=1/4, lty=2)
plot(freq.seq/n.yr, rec.spgram[freq.idx], type="l", lty=1, lwd=1, ylab="Weighted smoothing", xlab="Frequency")
abline(v=1/4, lty=2)
par(mfrow = c(1, 1))
# The peaks in these smoothed periodograms are much sharper than those produced using uniform smoothing.
# ---------------------------------------------------------------------------------
# Confidence intervals
# ---------------------------------------------------------------------------------
# The following code repeats the previous confidence intervals calculations on the smoothed periodograms with weighted smoothing. The special formula for degrees of freedom is
df <- 2/sum(wgts^2)
df
# Don't be thrown of by this being a non-integer value for degrees of freedom.
# Confidence intervals for the periodogram associated with the one-year (omega=1/12) cycles and four-year (omega=1/48) cycles are calculated as follows.
# The value associated with the one year cycle found at element 39 of the periodogram vector.
i.val <- 39
# Confidence intervals are calculated as follows
alpha <- 0.05
cutoff <- qchisq(p=c(alpha/2, 1-alpha/2), df=df)
# SOI time series
val <- soi.spgram[i.val]
lo.bnd <- df*val/cutoff[2]
hi.bnd <- df*val/cutoff[1]
print(paste("Point estimate: ", sprintf("%6.4f", val), sep=""))
print(paste(sprintf("%2.0f", (1-alpha)*100), "% confidence interval: [", sprintf("%6.4f", lo.bnd), ", ", sprintf("%6.4f", hi.bnd), "]", sep=""))
print("Log transform:")
print(paste("Point estimate: ", sprintf("%6.4f", log(val)), sep=""))
print(paste(sprintf("%2.0f", (1-alpha)*100), "% confidence interval: [", sprintf("%6.4f", log(lo.bnd)), ", ", sprintf("%6.4f", log(hi.bnd)), "]", sep=""))
# Fish population count time series
val <- rec.spgram[i.val]
lo.bnd <- df*val/cutoff[2]
hi.bnd <- df*val/cutoff[1]
print(paste("Point estimate: ", sprintf("%6.4f", val), sep=""))
print(paste(sprintf("%2.0f", (1-alpha)*100), "% confidence interval: [", sprintf("%6.4f", lo.bnd), ", ", sprintf("%6.4f", hi.bnd), "]", sep=""))
print("Log transform:")
print(paste("Point estimate: ", sprintf("%6.4f", log(val)), sep=""))
print(paste(sprintf("%2.0f", (1-alpha)*100), "% confidence interval: [", sprintf("%6.4f", log(lo.bnd)), ", ", sprintf("%6.4f", log(hi.bnd)), "]", sep=""))
# The value associated with the four year cycle found at element 10 of the periodogram vector.
i.val <- 10
# The associated confidence intervals are calculated as follows
# SOI time series
val <- soi.spgram[i.val]
lo.bnd <- df*val/cutoff[2]
hi.bnd <- df*val/cutoff[1]
print(paste("Point estimate: ", sprintf("%6.4f", val), sep=""))
print(paste(sprintf("%2.0f", (1-alpha)*100), "% confidence interval: [", sprintf("%6.4f", lo.bnd), ", ", sprintf("%6.4f", hi.bnd), "]", sep=""))
print("Log transform:")
print(paste("Point estimate: ", sprintf("%6.4f", log(val)), sep=""))
print(paste(sprintf("%2.0f", (1-alpha)*100), "% confidence interval: [", sprintf("%6.4f", log(lo.bnd)), ", ", sprintf("%6.4f", log(hi.bnd)), "]", sep=""))
# Fish population count time series
val <- rec.spgram[i.val]
lo.bnd <- df*val/cutoff[2]
hi.bnd <- df*val/cutoff[1]
print(paste("Point estimate: ", sprintf("%6.4f", val), sep=""))
print(paste(sprintf("%2.0f", (1-alpha)*100), "% confidence interval: [", sprintf("%6.4f", lo.bnd), ", ", sprintf("%6.4f", hi.bnd), "]", sep=""))
print("Log transform:")
print(paste("Point estimate: ", sprintf("%6.4f", log(val)), sep=""))
print(paste(sprintf("%2.0f", (1-alpha)*100), "% confidence interval: [", sprintf("%6.4f", log(lo.bnd)), ", ", sprintf("%6.4f", log(hi.bnd)), "]", sep=""))
# =================================================================================
# Linear filters
# =================================================================================
# The following user-defined function calculates the power transfer function from a given impulse response function, at a given frequency. The lag values associated with the impulse response function must also be provided.
power.transfer <- function(omega, ir.funct, ir.lag) {
imag.const <- sqrt(as.complex(-1))
n.lag <- length(ir.lag)
fr.funct <- 0
for (i.lag in 1:n.lag) {
fr.funct <- fr.funct + ir.funct[i.lag]*exp(-2*pi*imag.const*omega*ir.lag[i.lag])
}
pt.val <- Mod(fr.funct)^2
return(pt.val)
}
# The function below applies the linear-filter specifications to a given time series. Data values at times before or after the times of the measured time series are set to the sample mean.
filter.ts <- function(x.ts, ir.funct, ir.lag) {
n <- length(x.ts)
mu.hat <- mean(x.ts)
val.seq <- numeric(length=length(ir.lag))
y.ts <- x.ts
for (t in 1:n) {
idx.seq <- t-ir.lag
sub.idx.in <- which((idx.seq >= 1) & (idx.seq <= n))
val.seq[sub.idx.in] <- x.ts[idx.seq[sub.idx.in]]
sub.idx.out <- which((idx.seq < 1) | (idx.seq > n))
val.seq[sub.idx.out] <- mu.hat
y.ts[t] <- sum(ir.funct*val.seq)
}
return(y.ts)
}
# ---------------------------------------------------------------------------------
# High-pass filter
# ---------------------------------------------------------------------------------
# A high-pass filter that is equivalent to differencing is defined by the following specifications
ir.lag <- c(0, 1)
ir.funct <- c(1, -1)
# The code below produces a plot of the impulse response function.
min.lag <- min(ir.lag); max.lag <- max(ir.lag); rng.lag <- max.lag-min.lag
min.funct <- min(ir.funct); max.funct <- max(ir.funct); rng.funct <- max.funct-min.funct
plot(c(min.lag, max.lag), c(0, 0), type="l", lty=2, lwd=1, xlim=c(min.lag-0.1*rng.lag, max.lag+0.1*rng.lag), ylim=c(min.funct-0.1*rng.funct, max.funct+0.1*rng.funct), col="white", ylab="weight", xlab="", main="impulse response function")
for (i.lag in 1:length(ir.lag)) {
lines(ir.lag[i.lag]*c(1, 1), c(0, ir.funct[i.lag]), lty=1, lwd=3, col="blue")
}
abline(h=0, lty=2)
# A plot of the corresponding power transfer function is generated as follows
omega.seq <- seq(from=0, to=0.5,by=0.01)
pt.funct <- power.transfer(omega.seq, ir.funct, ir.lag)
plot(omega.seq, pt.funct, type="l", lty=1, lwd=1, xlab="frequency", ylab="", main="high-pass filter")
# The following code generates a plot of the SOI time series and a plot of the same time series passed through the filter.
y.ts <- filter.ts(soi, ir.funct, ir.lag)
par(mfrow = c(2, 1), mai=c(0.50,1.00,0.1,0.1)) # mai=c(bottom, left, top, right)
ts.plot(soi, type="l", lty=1, lwd=1, ylab="raw value", xlab="time")
ts.plot(y.ts, type="l", lty=1, lwd=1, ylab="filtered value", xlab="time")
par(mfrow = c(1, 1))
# The next set of code produces plots of periodograms for the SOI time series and the same time series passed through the filter.
n.yr <- 453/12
freq.seq <- 1:ceiling(6*n.yr)
freq.idx <- freq.seq+1
pt.funct <- power.transfer(freq.seq/453, ir.funct, ir.lag)
par(mfrow = c(2, 1), mai=c(0.50,1.00,0.1,0.1)) # mai=c(bottom, left, top, right)
plot(freq.seq/n.yr, soi.pgram[freq.idx], type="l", lty=1, lwd=1, ylab="raw value", xlab="Frequency")
abline(v=1/4, lty="dotted")
plot(freq.seq/n.yr, pt.funct*soi.pgram[freq.idx], type="l", lty=1, lwd=1, ylab="filtered value", xlab="Frequency")
abline(v=1/4, lty="dotted")
par(mfrow = c(1, 1))
# ---------------------------------------------------------------------------------
# Low-pass filter
# ---------------------------------------------------------------------------------
# A low-pass filter is defined from a modified Daniell kernel specified as follows
m <- 6
L <- 2*m + 1
ir.lag <- -m:m
ir.funct <- rep(x=0.5/m, times=L)
ir.funct[c(1,L)] <- 0.25/m
# The code below produces a plot of the impulse response function.
min.lag <- min(ir.lag); max.lag <- max(ir.lag); rng.lag <- max.lag-min.lag
min.funct <- min(ir.funct); max.funct <- max(ir.funct); rng.funct <- max.funct-min.funct
plot(c(min.lag, max.lag), c(0, 0), type="l", lty=2, lwd=1, xlim=c(min.lag-0.1*rng.lag, max.lag+0.1*rng.lag), ylim=c(min.funct-0.1*rng.funct, max.funct+0.1*rng.funct), col="white", ylab="weight", xlab="", main="impulse response function")
for (i.lag in 1:length(ir.lag)) {
lines(ir.lag[i.lag]*c(1, 1), c(0, ir.funct[i.lag]), lty=1, lwd=3, col="blue")
}
abline(h=0, lty=2)
# A plot of the corresponding power transfer function is generated as follows
omega.seq <- seq(from=0, to=0.5,by=0.01)
pt.funct <- power.transfer(omega.seq, ir.funct, ir.lag)
plot(omega.seq, pt.funct, type="l", lty=1, lwd=1, xlab="frequency", ylab="", main="low-pass filter")
# The following code generates a plot of the SOI time series and a plot of the same time series passed through the filter.
y.ts <- filter.ts(soi, ir.funct, ir.lag)
par(mfrow = c(2, 1), mai=c(0.50,1.00,0.1,0.1)) # mai=c(bottom, left, top, right)
ts.plot(soi, type="l", lty=1, lwd=1, ylab="raw value", xlab="time")
ts.plot(y.ts, type="l", lty=1, lwd=1, ylab="filtered value", xlab="time")
par(mfrow = c(1, 1))
# The next set of code produces plots of periodograms for the SOI time series and the same time series passed through the filter.
n.yr <- 453/12
freq.seq <- 1:ceiling(6*n.yr)
freq.idx <- freq.seq+1
pt.funct <- power.transfer(freq.seq/453, ir.funct, ir.lag)
par(mfrow = c(2, 1), mai=c(0.50,1.00,0.1,0.1)) # mai=c(bottom, left, top, right)
plot(freq.seq/n.yr, soi.pgram[freq.idx], type="l", lty=1, lwd=1, ylab="raw value", xlab="Frequency")
abline(v=1/4, lty="dotted")
plot(freq.seq/n.yr, pt.funct*soi.pgram[freq.idx], type="l", lty=1, lwd=1, ylab="filtered value", xlab="Frequency")
abline(v=1/4, lty="dotted")
par(mfrow = c(1, 1))
# 1)
x.ts <- read.table('astronomy A.txt', header=FALSE)
x.ts <- x.ts$V1
n = length(x.ts)
m = 2
n.lag <- (2*m)+1
wgts <- rep(x=1, times=n.lag)/n.lag
x.hat.ts <- ma.smooth(x.ts, wgts)
x.hat.ts[32]          # 54.86
# 2)
wgts <- Gauss.wgts(m)
x.hat.ts <- ma.smooth(x.ts, wgts)
x.hat.ts[12]         # 50.82538
# 3)
x.vect <- as.matrix(x.ts)
Z.mat <- cbspline.regmat(n, nspline=8, ratio=1.3)
result <- reg.summary(x.vect, Z.mat)
result$mu[13]      # 44.35398
# 4)
time.seq <- 1:n
omega <- 5/46      # 46 is n
r <- dim(Z.mat)[2]
Z.mat <- cbind(Z.mat, matrix(data=0, nrow=n, ncol=2))
Z.mat[,r+1] <- cos(2*pi*omega*time.seq)
Z.mat[,r+2] <- sin(2*pi*omega*time.seq)
r <- r + 2
result <- reg.summary(x.vect, Z.mat)
result$mu[13]           # 53.01345
# 5)
wgts <- Gauss.wgts(m)
x.hat.ts <- reg.smooth(x.ts, wgts)
x.hat.ts[23]            # 55.65723
# 6)
alpha = c(1.15, 0.55)
Er2.form <- alpha[1] / (1 - alpha[2])
Er2.form         # 2.555556
# 7)
Er4.form <- 3*alpha[1]^2*(1+alpha[2]) / ((1 - alpha[2])*(1-3*alpha[2]^2))
kappa.form <- Er4.form / (Er2.form)^2
kappa.form           # 22.62162
# 8)
n = 10^5
zcut = 2.17
arch.data <- arch.sim(n=n, alpha=alpha)
cutoff <- zcut*sqrt(Er2.form)
table(abs(arch.data$ts) > cutoff) / n           # 0.03401
#1)
# xt=3.0cos(2πωt − 0.5)
# A= 3.0, phi = -0.5
# U1 = Acos(phi)
u1 = 3 * cos(-0.5)
u1    # 2.632748
#2)
phi <- c(-1, -0.3)
theta <- c(-0.4)
sigw <- 5
omega <- 0.26
imag.const <- sqrt(as.complex(-1))
p <- length(phi)
q <- length(theta)
n.val <- length(omega)
val.seq <- numeric(length=n.val)
for (i.val in 1:n.val) {
numer <- Mod(1 + sum(theta*exp(-2*(1:q)*pi*imag.const*omega[[i.val]])))
denom <- Mod(1 - sum(phi*exp(-2*(1:p)*pi*imag.const*omega[[i.val]])))
val.seq[i.val] <- (sigw*numer/denom)^2
}
val.seq           # 22.72351
#3)
phi <- c(0.75, -0.9)
sigw <- 7.5
omega.seq <- seq(0,0.5,by=0.0001)
spdens <- ar.spdens(omega.seq, phi, sigw)          # 6a line 202
max(spdens)
plot(omega.seq, spdens, type="l", main="", xlab="frequency", ylab="")
index3 <- which(spdens == max(spdens))
ans <- 0.0001 * index3
ans      # 0.1853
#4)
x.ts <- read.table('environ C.txt', header=FALSE)
x.ts <- x.ts$V1
n <- length(x.ts)
x.dft <- fft(x.ts) / sqrt(n)
x.dft
#k/n = 8/59 #so looking for (k+1)th entry which is 9th entry in the dft vector
x.dft[9]
add <- abs(Re(x.dft[9])) + abs(Im(x.dft[9]))
add  # 9.640275
# 5)
x.pgram <- Mod(x.dft)^2
x.pgram[9]          # 47.03155
#6)
m <-4
L <- 2*m + 1
wgts <- rep(x=1/L, times=L)
x.spgram <- smooth.pgram(x.pgram, wgts)     #smooth.pgram in 6b line 59
x.spgram[9]           # 90.02003
# 7)
# 2 iterations
# line 179 6b
L <- 9
base.wgts <- c(0.35, 0.45, 0.2)
n.iter <- 2
wgts <- Daniell.wgts(base.wgts, n.iter)
x.spgram <- smooth.pgram(x.pgram, wgts)
x.spgram[9]     # 122.5231
#8)
df <- 2/sum(wgts^2)
df          # 10.47466
#9)
m <- 4
L <- 2*m + 1
omega <- 8/59
ir.lag <- -m:m
pt.funct <- power.transfer(omega, wgts, ir.lag)        # line 382 6b
pt.funct       # 0.2043917
#10)
y.ts <- filter.ts(x.ts, wgts, ir.lag)             # line 395 6b
y.ts[13]        # 4.227036
#1)
# xt=3.0cos(2πωt − 0.5)
# A= 3.0, phi = -0.5
# U1 = Acos(phi)
u2 = -4 * sin(-2.1)
u2    # 2.632748
ar.sim <- function(n, phi, sigw, x0=NA) {
p <- length(phi)
wn.samp <- rnorm(n=n, mean=0, sd=sigw)
if (is.na(x0)) {
pastx <- rep(x=0, times=p)
} else {
pastx <- c(x0, rep(x=0, times=p-length(x0)))
}
ar.samp <- numeric(length=n)
for (t in 1:n) {
ar.samp[t] <- sum(phi*pastx) + wn.samp[t]
pastx <- c(ar.samp[t], pastx[1:p-1])
}
ar.ts <- ts(ar.samp)
return(ar.ts)
}
phi1 <- -0.9
phi2 <- -0.2
phi <- c(phi1, phi2)
n <- 75
time.seq <- 1:n
omega.seq <- 0.22
sigw <- 10
par(mfrow = c(2, 1), mai=c(0.9,0.1,0.1,0.1)) # mai=c(bottom, left, top, right)
ar.ts <- ar.sim(n, phi, sigw)
plot(ar.ts, type="l", main="", xlab="time", ylab="")
spdens <- ar.spdens(omega.seq, phi, sigw)
spdens
phi <- c(phi1, phi2)
ar.ts <- ar.sim(n, phi, 10)
spdens <- ar.spdens(0.22, phi, 10)
spdens
# 6)
alpha = c(1.2, 0.55)
Er2.form <- alpha[1] / (1 - alpha[2])
Er2.form         # 2.555556
# 7)
Er4.form <- 3*alpha[1]^2*(1+alpha[2]) / ((1 - alpha[2])*(1-3*alpha[2]^2))
Er4.form
#1)
# xt=3.0cos(2πωt − 0.5)
# A= 3.0, phi = -0.5
# U1 = Acos(phi)
u2 = -4 * sin(-2.1)
u2    # 2.632748
